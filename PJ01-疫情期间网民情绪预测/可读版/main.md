## 1. é¡¹ç›®ä»‹ç»

### 1.1 é¡¹ç›®èƒŒæ™¯
æœ¬é¡¹ç›®æ˜¯æˆ‘å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†çš„ç¬¬ä¸€ä¸ªé¡¹ç›®ï¼Œè¿è¡Œç¯å¢ƒæ˜¯[ç™¾åº¦é£æ¡¨å¹³å°](https://aistudio.baidu.com/aistudio/index)ã€‚

é¡¹ç›®å†…å®¹ä¸»è¦æ˜¯ä½¿ç”¨å…³äº[ç–«æƒ…æœŸé—´å¾®åšè¯„è®ºæ•°æ®é›†](https://aistudio.baidu.com/aistudio/datasetdetail/130719/0)ï¼Œåˆ©ç”¨é£æ¡¨çš„ `PaddleNLP` è‡ªç„¶è¯­è¨€å¤„ç†å¼€å‘åº“ï¼Œä»¥åŠé¢„è®­ç»ƒæ¨¡å‹ `ERNIE` å®Œæˆå¯¹æƒ…ç»ªè¯†åˆ«æ¨¡å‹çš„è®­ç»ƒï¼Œæœ€åè¿›è¡Œã€é¢å‘å¯¹è±¡ã€æµ‹è¯•ï¼Œæ•ˆæœè¿˜ä¸é”™ï¼Œå¤§å®¶æœ‰å…´è¶£å¯ä»¥è¯•è¯•çœ‹ğŸ˜œã€‚


### 1.2 æ•°æ®é›†æ¥æº

æœ¬æ•°æ®é›†æ¥æºæ˜¯èµ›äº‹[ç–«æƒ…æœŸé—´ç½‘æ°‘æƒ…ç»ªè¯†åˆ«](https://www.datafountain.cn/competitions/423)ï¼Œæ­¤å¤„å°†æ•°æ®é›†è§£å‹è‡³æœ¬é¡¹ç›® `/work` ç›®å½•ä¸‹ã€‚

æ•°æ®é›†æ˜¯ä¾æ®ä¸â€œæ–°å† è‚ºç‚â€ç›¸å…³çš„230ä¸ªä¸»é¢˜å…³é”®è¯è¿›è¡Œæ•°æ®é‡‡é›†ï¼ŒæŠ“å–äº†2020å¹´1æœˆ1æ—¥â€”2020å¹´2æœˆ20æ—¥æœŸé—´å…±è®¡100ä¸‡æ¡å¾®åšæ•°æ®ï¼Œå¹¶å¯¹å…¶ä¸­10ä¸‡æ¡æ•°æ®è¿›è¡Œäººå·¥æ ‡æ³¨ï¼Œæ ‡æ³¨åˆ†ä¸ºä¸‰ç±»ï¼Œåˆ†åˆ«ä¸ºï¼š**1ï¼ˆç§¯æï¼‰ï¼Œ0ï¼ˆä¸­æ€§ï¼‰å’Œ-1ï¼ˆæ¶ˆæï¼‰**ã€‚

> âœ‹éœ€è¦æ³¨æ„çš„æ˜¯ï¼šç›´æ¥forkæœ¬é¡¹ç›®çš„æ•°æ®é›†æ˜¯æ²¡æœ‰é—®é¢˜çš„ï¼Œä½†æ˜¯é€‰æ‹©ä½¿ç”¨ç›®å‰AI studio[åŒç±»åŠ ç²¾æ•°æ®é›†](https://aistudio.baidu.com/aistudio/datasetdetail/22724/0)ä¸­çš„ `train_ dataset.zip` åå­—æœ‰ç©ºæ ¼ï¼Œè¿›è¡Œè§£å‹ä¹‹å‰éœ€è¦é‡å‘½åå°†ç©ºæ ¼å»é™¤ï¼Œæˆ–ä½¿ç”¨å¼•å·ã€‚


```python
# # å°†æ•°æ®é›†è§£å‹åˆ° /work ç›®å½•ä¸‹(é¦–æ¬¡è§£å‹å–æ¶ˆæ³¨é‡Š)
# !unzip -oq data/data130719/train_dataset.zip -d work/
# !unzip -oq data/data130719/test_dataset.zip -d work/
```


```python
# å°†æäº¤æ•°æ®é›†å¤åˆ¶åˆ° /workä¸‹
!cp data/data130719/submit_example.csv work/submit_example.csv
```


```python
# æŸ¥çœ‹æ•°æ®é›†æ‰€åœ¨ç›®å½•ç»“æ„
!tree work/ -a
```

    work/
    â”œâ”€â”€ .ipynb_checkpoints
    â”‚Â Â  â”œâ”€â”€ nCov_10k_test-checkpoint.csv
    â”‚Â Â  â””â”€â”€ test-checkpoint.txt
    â”œâ”€â”€ nCoV_100k_train.labled.csv
    â”œâ”€â”€ nCov_10k_test.csv
    â”œâ”€â”€ nCoV_900k_train.unlabled.csv
    â”œâ”€â”€ submit_example.csv
    â”œâ”€â”€ test.txt
    â”œâ”€â”€ train.txt
    â””â”€â”€ valid.txt
    
    1 directory, 9 files


### 1.3 æ•°æ®é›†ä¿¡æ¯

* **è®­ç»ƒæ•°æ®é›†**æ–‡ä»¶åç§°ï¼šnCoV_100k_train.labled.csv
	åŒ…å«100000æ¡å¾®åšç”¨æˆ·å‘å¸ƒçš„å¾®åšå†…å®¹, å…·ä½“å­—æ®µå¦‚ä¸‹ï¼š

  * å¾®åšidï¼Œæ ¼å¼ä¸ºæ•´å‹ã€‚
  * å¾®åšå‘å¸ƒæ—¶é—´ï¼Œæ ¼å¼ä¸º `xxæœˆxxæ—¥ xx:xx`ã€‚
  * å‘å¸ƒäººè´¦å·ï¼Œæ ¼å¼ä¸ºå­—ç¬¦ä¸²ã€‚
  * å¾®åšä¸­æ–‡å†…å®¹ï¼Œæ ¼å¼ä¸ºå­—ç¬¦ä¸²ã€‚
  * å¾®åšå›¾ç‰‡ï¼Œæ ¼å¼ä¸ºurlè¶…é“¾æ¥ï¼Œ`[ ]`ä»£è¡¨ä¸å«å›¾ç‰‡ã€‚
  * å¾®åšè§†é¢‘ï¼Œæ ¼å¼ä¸ºurlè¶…é“¾æ¥ï¼Œ`[ ]`ä»£è¡¨ä¸å«è§†é¢‘ã€‚
  * æƒ…æ„Ÿå€¾å‘ï¼Œå–å€¼ä¸º `{1,0,-1}`ã€‚

* **æµ‹è¯•æ•°æ®é›†**æ–‡ä»¶åç§°ï¼šwork/nCov_10k_test.csv

	åŒ…å«10000æ¡å¾®åšç”¨æˆ·å‘å¸ƒçš„å¾®åšå†…å®¹ï¼Œæ¯æ¡æ•°æ®åŒ…æ‹¬`'å¾®åšid', 'å¾®åšå‘å¸ƒæ—¶é—´', 'å‘å¸ƒäººè´¦å·', 'å¾®åšä¸­æ–‡å†…å®¹', 'å¾®åšå›¾ç‰‡', 'å¾®åšè§†é¢‘'`ã€‚

## 2. æ•°æ®æ¢ç´¢å’Œé¢„å¤„ç†

ç”±äºæ•°æ®é›†æ˜¯ä½¿ç”¨ `GB2312` ç¼–ç ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨å¯¹å…¶è¿›è¡Œé‡æ–°ç¼–ç å¹¶ä¿å­˜ã€‚

åŸå§‹æ•°æ®é›†ä¸­å­˜åœ¨è§£ç é”™è¯¯ï¼Œæ˜¯å¾®åšä¸€äº›ç‰¹æ®Šç¬¦å·æˆ–æ ‡ç­¾å¼•èµ·ï¼Œéš¾ä»¥ä½¿ç”¨å¸¸è§„ç¼–ç è¿›è¡Œè§£ç ï¼Œåœ¨æ­¤å¯¹å…¶è¿›è¡Œå¿½ç•¥ã€‚


```python
# # å¯¹æ–‡ä»¶è¿›è¡Œé‡æ–°ç¼–ç ï¼ˆä»…é¦–æ¬¡è§£å‹æ–‡ä»¶åè¿è¡Œï¼‰
# def re_code(path):
#    with open(path, 'r', encoding='GB2312', errors='ignore') as f:
#        lines = f.readlines()
#    with open(path, 'w', encoding='utf-8') as fw:
#         fw.write(''.join(lines))

# re_code('work/nCoV_100k_train.labled.csv')
# re_code('work/nCov_10k_test.csv')
```

### 2.1 è¯»å–æ•°æ®

ä½¿ç”¨ `pandas` è¯»å–è®­ç»ƒé›†å’Œæ•°æ®é›†çš„æ•°æ®ã€‚

> âœ‹åœ¨é£æ¡¨å¹³å°è¿è¡Œæ—¶ï¼Œè‹¥éœ€è¦åœ¨ç»˜åˆ¶å›¾åƒæ—¶ä½¿ç”¨ä¸­æ–‡ï¼Œåˆ™éœ€è¦è¿›è¡Œè®¾ç½®ï¼Œæ™®é€šçš„è®¾ç½® `plt.rcParams["font.sans-serif"]=["SimHei"]` å’Œ `plt.rcParams["axes.unicode_minus"]=False`å¹¶ä¸èƒ½åœ¨æ­¤ç®€å•è§£å†³é—®é¢˜ã€‚è‹¥éœ€è¦æŠ˜è…¾ğŸ‘ï¼Œåˆ™å¯ä»¥å‚è€ƒ[è§£å†³AI Studioä¸­matplotlibæ±‰å­—æ˜¾ç¤ºé—®é¢˜](https://aistudio.baidu.com/aistudio/projectdetail/390895)ã€‚
>
> ä¸è¿‡åœ¨ **AI Studio** çš„ä¸€æ¬¡å‡çº§ä¸­ï¼Œ**æ–°å¢æ–‡æ³‰é©¿ä¸­æ–‡å­—ä½“**ï¼Œå®˜æ–¹ğŸ˜˜ç»™å‡ºå…·ä½“ç”¨æ³•å‚è€ƒ[Ubuntu ä¸­ä½¿ç”¨ matplotlib ç”»å›¾å¦‚ä½•æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡](https://www.jianshu.com/p/7d4f88c62815)ï¼Œä¹Ÿå°±æ˜¯æ­¤å¤„ä½¿ç”¨çš„æ–¹æ³•ã€‚


```python
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

# è®¾ç½®ä¸­æ–‡å­—ä½“
myfont = matplotlib.font_manager.FontProperties(fname='/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc')

import warnings
# è¿‡æ»¤æŠ¥è­¦ä¿¡æ¯
warnings.filterwarnings("ignore", category=Warning)
```


```python
# è¯»å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†æ•°æ®
df_train = pd.read_csv('work/nCoV_100k_train.labled.csv')
df_test = pd.read_csv('work/nCov_10k_test.csv')
```


```python
# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
print(f"è®­ç»ƒé›†çš„æ•°æ®å¤§å°ä¸º{df_train.shape}")
print(f"æµ‹è¯•é›†çš„æ•°æ®å¤§å°ä¸º{df_test.shape}")
print(f"æ•°æ®å­—æ®µä¸º{df_train.columns}")
print(f"æ•°æ®å­—æ®µä¸º{df_test.columns}")
```

    è®­ç»ƒé›†çš„æ•°æ®å¤§å°ä¸º(100000, 7)
    æµ‹è¯•é›†çš„æ•°æ®å¤§å°ä¸º(10000, 6)
    æ•°æ®å­—æ®µä¸ºIndex(['å¾®åšid', 'å¾®åšå‘å¸ƒæ—¶é—´', 'å‘å¸ƒäººè´¦å·', 'å¾®åšä¸­æ–‡å†…å®¹', 'å¾®åšå›¾ç‰‡', 'å¾®åšè§†é¢‘', 'æƒ…æ„Ÿå€¾å‘'], dtype='object')
    æ•°æ®å­—æ®µä¸ºIndex(['å¾®åšid', 'å¾®åšå‘å¸ƒæ—¶é—´', 'å‘å¸ƒäººè´¦å·', 'å¾®åšä¸­æ–‡å†…å®¹', 'å¾®åšå›¾ç‰‡', 'å¾®åšè§†é¢‘'], dtype='object')

```python
# ç®€å•æŸ¥çœ‹ä¸€ä¸‹æ•°æ®
df_train.head(2).append(df_train.tail(2))
```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>å¾®åšid</th>
      <th>å¾®åšå‘å¸ƒæ—¶é—´</th>
      <th>å‘å¸ƒäººè´¦å·</th>
      <th>å¾®åšä¸­æ–‡å†…å®¹</th>
      <th>å¾®åšå›¾ç‰‡</th>
      <th>å¾®åšè§†é¢‘</th>
      <th>æƒ…æ„Ÿå€¾å‘</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4456072029125500</td>
      <td>01æœˆ01æ—¥ 23:50</td>
      <td>å­˜æ›¦1988</td>
      <td>å†™åœ¨å¹´æœ«å†¬åˆå­©å­æµæ„Ÿçš„ç¬¬äº”å¤©ï¼Œæˆ‘ä»¬ä»ç„¶æ²¡æœ‰å¿˜è®°çƒ­æƒ…æ‹¥æŠ±è¿™2020å¹´çš„ç¬¬ä¸€å¤©ã€‚å¸¦ç€ä¸€ä¸è¿·ä¿¡ï¼Œæ—©...</td>
      <td>['https://ww2.sinaimg.cn/orj360/005VnA1zly1gah...</td>
      <td>[]</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4456074167480980</td>
      <td>01æœˆ01æ—¥ 23:58</td>
      <td>LunaKrys</td>
      <td>å¼€å¹´å¤§æ¨¡å‹â€¦ç´¯åˆ°ä»¥ä¸ºè‡ªå·±å‘çƒ§äº†è…°ç–¼è†ç›–ç–¼è…¿ç–¼èƒ³è†Šç–¼è„–å­ç–¼#Lunaçš„Krystallife#?</td>
      <td>[]</td>
      <td>[]</td>
      <td>-1</td>
    </tr>
    <tr>
      <th>99998</th>
      <td>4472950743017610</td>
      <td>02æœˆ17æ—¥ 13:40</td>
      <td>åŒ»åº“</td>
      <td>ã€æ–°å† ç–«æƒ…æœ€å—å…³æ³¨çš„åä¸€ç¯‡è‹±æ–‡æ ¸å¿ƒæœŸåˆŠè®ºæ–‡å…¨è§£æã€‘æœ¬æ–‡æ•´ç†äº†å…³äºæ–°å‹å† çŠ¶ç—…æ¯’æœ€å—å…³æ³¨çš„åä¸€ç¯‡...</td>
      <td>[]</td>
      <td>[]</td>
      <td>1</td>
    </tr>
    <tr>
      <th>99999</th>
      <td>4472870103356260</td>
      <td>02æœˆ17æ—¥ 08:19</td>
      <td>æœ‰åº¦ä¸ºç‹</td>
      <td>ä»è™è æºå¸¦çš„å† çŠ¶ç—…æ¯’å˜å¼‚æˆ2019-nCoVå† çŠ¶ç—…æ¯’,æ€æ ·æ‰èƒ½å‘ç”Ÿå˜å¼‚å‘¢ï¼Ÿæœ‰ä¸¤ç§å¯èƒ½1.è‡ªç„¶...</td>
      <td>[]</td>
      <td>[]</td>
      <td>0</td>
    </tr>
  </tbody>
</table>


### 2.2 æ ‡ç­¾åˆ†å¸ƒ

å¯¹äºè®­ç»ƒé›†ï¼Œç”¨æˆ·æƒ…æ„Ÿå·²ç»è¿›è¡Œäº†æ ‡æ³¨ï¼Œå¹¶åˆ†ä¸ºä¸‰ç±»ï¼Œåˆ†åˆ«æ˜¯ï¼š**1ï¼ˆç§¯æï¼‰ï¼Œ0ï¼ˆä¸­æ€§ï¼‰å’Œ-1ï¼ˆæ¶ˆæï¼‰**ã€‚

ä½†æ˜¯æ•°æ®é›†ä¸­å­˜åœ¨éƒ¨åˆ†å¼‚å¸¸æ•°æ®ï¼Œå°†å…¶åˆ é™¤ã€‚

è¿›è€Œç»˜åˆ¶æŸ±çŠ¶å›¾å¯ä»¥å‘ç°ï¼šå¤§éƒ¨åˆ†æ ·æœ¬è¡¨ç°å‡ºä¸­æ€§æƒ…ç»ªï¼Œå…¶æ¬¡æ˜¯ç§¯ææƒ…ç»ªï¼Œè€Œæ¶ˆææƒ…ç»ªæ ·æœ¬æœ€å°ã€‚


```python
# åˆ é™¤æå°‘é‡ï¼ˆ7æ¡ï¼‰å¼‚å¸¸æ•°æ®ï¼Œä¿ç•™æ­£å¸¸æƒ…æ„Ÿå€¾å‘æ ‡ç­¾
df_train = df_train[df_train['æƒ…æ„Ÿå€¾å‘'].map(lambda x: x == '1' or x == '-1' or x == '0')]
df_train.shape

df_train['æƒ…æ„Ÿå€¾å‘'].value_counts(normalize=True).plot.bar(rot=0)
plt.title("ç”¨æˆ·æƒ…æ„Ÿåˆ†å¸ƒ", fontproperties=myfont, fontsize=16)
plt.show()
```


â€‹    
![png](output_12_0.png)
â€‹    


### 2.3 æ–‡æœ¬é•¿åº¦

å¾®åšå†…å®¹åŒ…æ‹¬`å¾®åšä¸­æ–‡å†…å®¹ã€å¾®åšå›¾ç‰‡ã€å¾®åšè§†é¢‘`ä¸‰éƒ¨åˆ†ï¼Œä½†å¯¹äºæˆ‘ä»¬æ¥è¯´ï¼Œåªå…³å¿ƒç”¨æˆ·å‘è¡¨çš„æ–‡æœ¬ä¿¡æ¯ï¼Œæ‰€ä»¥åœ¨æ­¤å¯¹æ–‡æœ¬è¿›è¡ŒæŸ¥çœ‹

å¯ä»¥å‘ç°ï¼šå¹³å‡é•¿åº¦ä¸º`87`ä¸ªå­—ç¬¦ï¼Œæœ€å¤§é•¿åº¦ä¸º`241`ä¸ªå­—ç¬¦ï¼Œå¤§éƒ¨åˆ†æ–‡æœ¬é•¿åº¦å¤„äºåœ¨`150`ä¸ªå­—ç¬¦ä»¥ä¸‹ï¼Œå‘ˆ**åŒå³°åˆ†å¸ƒ**ã€‚


```python
df_train.loc[:, 'å¾®åšä¸­æ–‡å†…å®¹'] = df_train.loc[:, 'å¾®åšä¸­æ–‡å†…å®¹'].astype(str)
text_length = df_train.loc[:, 'å¾®åšä¸­æ–‡å†…å®¹'].map(lambda x: len(x))
text_length.name = 'ä¸­æ–‡å†…å®¹é•¿åº¦'
```


```python
# è°ƒèŠ‚å›¾åƒå¤§å°, æ¸…æ™°åº¦
plt.figure(figsize=(6,3), dpi=100)
# ç»˜åˆ¶ç›´æ–¹å›¾
sns.distplot(text_length)
plt.title('æ–‡æœ¬é•¿åº¦åˆ†å¸ƒæƒ…å†µ', fontproperties=myfont, fontsize=16)
plt.xlabel('æ–‡æœ¬é•¿åº¦', fontproperties=myfont, fontsize=12)
plt.show()
```


![png](output_15_0.png)
    

```python
text_length.describe()
```




    count    99913.000000
    mean        86.978661
    std         49.521746
    min          1.000000
    25%         42.000000
    50%         86.000000
    75%        139.000000
    max        241.000000
    Name: ä¸­æ–‡å†…å®¹é•¿åº¦, dtype: float64



### 2.4 åˆ’åˆ†æ•°æ®é›†

åœ¨åŸæœ¬æ•°æ®é›†ä¸­å­˜åœ¨å¾ˆå¤šä¸éœ€è¦çš„å­—æ®µï¼Œä»…éœ€è¦ä¿ç•™ `å¾®åšä¸­æ–‡å†…å®¹` å’Œ `å¾®åšä¸­æ–‡å†…å®¹` å³å¯ã€‚

å¹¶å°†æä¾›çš„æ•´ä¸ªè®­ç»ƒé›†åˆ’åˆ†ä¸ºï¼šè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚å¹¶ä¿å­˜ä¸ºtxtæ–‡ä»¶


```python
# ä½¿ç”¨ train_test_split è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
from sklearn.model_selection import train_test_split

train_labled = df_train[['å¾®åšä¸­æ–‡å†…å®¹', 'æƒ…æ„Ÿå€¾å‘']]
test = df_test[['å¾®åšä¸­æ–‡å†…å®¹']]
train, valid = train_test_split(train_labled, test_size=0.2, random_state=10086)
train.to_csv('work/train.txt', index=False, header=False, sep='\t')
valid.to_csv('work/valid.txt', index=False, header=False, sep='\t')
test.to_csv('work/test.txt', index=False, header=False, sep='\t')
```

### 2.5 ä½¿ç”¨load_datasetå¯¼å…¥æ•°æ®

ä¸ºäº†ä¿æŒæ•°æ®å’Œpaddlenlpé»˜è®¤æ•°æ®é›†ä¸€è‡´ï¼Œ ä½¿ç”¨ `paddlenlp.datasets.load_dataset` ä»æœ¬åœ°æ–‡ä»¶ä¸­å¯¼å…¥æ•°æ®ã€‚

éœ€è¦è‡ªå®šä¹‰ `read_out` æ–¹æ³•æ¥è¿›è¡Œæ•°æ®æ ¼å¼å¤„ç†ã€‚

> âœ‹æ³¨æ„ï¼šä½†æ˜¯ç”±äºåç»­åœ¨è®¡ç®—æŸå¤±`loss = criterion(logits, labels)`çš„æ—¶å€™ä¸€ç›´æŠ¥ä¸€ä¸ª`-1`çš„é”™è¯¯, æ‰€ä»¥è¿™é‡Œå°†ç”¨æˆ·æƒ…æ„Ÿæ ‡ç­¾ä¿®æ”¹ä¸º**2ï¼ˆç§¯æï¼‰ï¼Œ1ï¼ˆä¸­æ€§ï¼‰å’Œ0ï¼ˆæ¶ˆæï¼‰**ï¼Œä½†ä¸å½±å“æ¨¡å‹ã€‚å…·ä½“åŸå› ä¸æ˜¯éå¸¸æ˜ç™½ï¼Œè‹¥æœ‰å¤§ä½¬æ¸…æ¥šï¼Œæ¬¢è¿ç•™è¨€æŒ‡ç‚¹ğŸ˜˜ã€‚


```python
import paddle
import paddlenlp as ppnlp
from paddlenlp.datasets import load_dataset

def read_out(data_path):
    """
    ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†æœ¬åœ°åŠ è½½ï¼Œè¯»å–æ•´ç†å¥½çš„æ•°æ®é›†
    """
    with open(data_path, 'r', encoding='utf-8') as f:
        for line in f:
            line_stripped = line.strip().split('\t')
            if not line_stripped:
                break
            if len(line_stripped) == 2:
                text = line_stripped[0]
                tags = int(line_stripped[1]) + 1  # ä½¿æ ‡ç­¾å˜æˆ 0-æ¶ˆæï¼Œ 1-ä¸­æ€§ï¼Œ 2-ç§¯æ
            else:
                text = line_stripped
                tags = []
            yield {"text": text, "label": tags}


# åˆ†åˆ«æ ¹æ®è‡ªå®šä¹‰çš„è¯»å–æ–¹æ³•ï¼Œä»æ–‡ä»¶ä¸­è·å¾—è®­ç»ƒå’ŒéªŒè¯æ•°æ®
train_ds = load_dataset(read_out, data_path='work/train.txt', lazy=False)
dev_ds = load_dataset(read_out, data_path='work/valid.txt', lazy=False)
```

### 2.6 æ•°æ®é›†æµ‹è¯•

ä¸»è¦æ˜¯æµ‹è¯•åŠ è½½æ•°æ®çš„æ–¹æ³•æ˜¯å¦å¯è¡Œï¼Œå¹¶è§‚å¯Ÿæ•°æ®çš„æ ¼å¼ç­‰åŸºæœ¬æƒ…å†µã€‚


```python
print('=============æµ‹è¯•è®­ç»ƒé›†=============')
for data in train_ds.data[:3]:
    print(data)

print('=============æµ‹è¯•éªŒè¯é›†=============')
for data in dev_ds.data[:3]:
    print(data)
```

    =============æµ‹è¯•è®­ç»ƒé›†=============
    {'text': 'è¿™å‡ å¤©åšå¾—æœ€å¤šçš„è¡¨æƒ…æ˜¯ï¼Œå‡¶ï¼Œç”Ÿæ°”ï¼Œçš±çœ‰ï¼Œé¢ç›®ç‹°ç‹ï¼Œä¸»è¦æ˜¯æ˜¾ç¤ºå‡ºæˆ‘çš„æ°”åŠ¿ä½†å¥½ç´¯å‘€æ™šä¸Šæœ‰ä¸¤åªç‹—æ²¡ç‰µç»³çš„ï¼Œæˆ‘å’Œé˜¿ç¦å…ˆåœ¨è‰åªé‚£é‡Œç«™ç€ï¼Œçªç„¶åé¢å°±æ¥å£°éŸ³æŠŠæˆ‘å“ç€äº†ï¼Œä¸¤ä¸ªç‹—å­å…¶å®çœ‹ä¸Šå»ä¹ŸæŒºæ¼‚äº®å¯çˆ±ã€‚å°±æ˜¯ä¸€ç›´è¿½ç€é˜¿ç¦ï¼Œé˜¿ç¦å«å¾—å‰å®³ï¼Œæˆ‘ä¸€ç›´æ‹‰ç€é˜¿ç¦å›å®¶ï¼Œæœ¬æ¥é˜¿ç¦éƒ½å¹³é™ä¸‹æ¥äº†ï¼Œç»“æœå…¶ä¸­?å±•å¼€å…¨æ–‡c', 'label': 1}
    {'text': '#å¤©å¤©å‘ä¸Š#å“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå“ˆå¤©å¤©å‘ä¸Šå¤ªä¼˜ç§€äº†ï¼Œäº‘å½•åˆ¶ï¼ŒæœŸå¾…å•Š?', 'label': 2}
    {'text': 'å¯¹äºè¿™æ¬¡ç—…æ¯’æˆ˜å½¹ï¼Œä»ç›®å‰çš„æ•°æ®æ¥çœ‹ï¼Œè‡´æ­»ç‡ä¸€ç›´ç»´æŒæ¯”è¾ƒä½çš„çŠ¶æ€ï¼Œæ¹–åŒ—æœ¬èº«å‰æœŸå‡†å¤‡å·¥ä½œç­‰ä¸è¶³å¯¼è‡´ç—…æ­»ç‡ç›¸å¯¹é«˜ç‚¹ï¼Œä½†çœå¤–å’Œå›½å¤–ï¼Œç—…æ­»ç‡ä¸€ç›´æ§åˆ¶åœ¨æä½æ°´å¹³ã€‚02DYxHg03ã€‚å¤–ï¼Œè¿‘æœŸç™½å²©æ¾é‚€è¯·æµè¡Œç—…å­¦å®¶å´å°Šå‹è°ˆç—…æ­»ç‡çš„æ—¶å€™å°±ç»™åˆ°è¿™æ ·çš„æ•°æ®ï¼šç»è¿‡7000å¤šç—…ä¾‹çš„åˆ†æ,1,å°äº30å²çš„åŸºæœ¬æ²¡æœ‰æ­»äº¡ã€‚2,40è‡³?å±•å¼€å…¨æ–‡c', 'label': 1}
    =============æµ‹è¯•éªŒè¯é›†=============
    {'text': '//@ç§¦tå¢¨://@è´å‹’ç‹duki://@è¿›å‡»çš„ç†Šçˆ¸çˆ¸:éƒ½æ˜¯ä¸­å›½äºº//@Makerforce:ä¸ä¸€æ ·çš„ä¸­å›½ã€‚ä¸œåŒ—ä¸‰çœä¸åˆ†å®¶ï¼Œæ±Ÿè‹åä¸‰å¤ªä¿å„è‡ªä¸ºæ”¿å……åˆ†ä½“ç°äº†å…±å’Œå›½çš„å¤šæ ·å‹', 'label': 2}
    {'text': '#æ‘©ç™»å…„å¼Ÿæ­¦æ±‰æ¼”å”±ä¼š#??#å…ƒè¸å•»å¤¯é”‡æ¦±è·¤é’…#??æ‘©ç™»å…„å¼Ÿæ‘©ç™»å…„å¼Ÿmdxdåˆ˜å®‡å®lynæ£šä¸»å®å“¥é™ªä½ çš„ç¬¬äºŒä¸ªè·¨å¹´ï¼Œè¿™ä¸€å¹´ä½ æ”¶è·äº†å¥½å¤šæˆç»©ï¼Œæ¼”å”±ä¼šï¼Œä¸“è¾‘ï¼Œç”µè§†å‰§ï¼Œå„ä¸ªæ´»åŠ¨ï¼ŒçœŸçš„ç‰¹åˆ«æ£’ï¼Œ2020å¹´ç»§ç»­åŠ æ²¹åŠªåŠ›ï¼Œæˆ‘ä»¬è¿˜ä¼šé™ªåœ¨ä½ çš„èº«è¾¹ä¸€ç›´æ”¯æŒä½ ã€‚@MD_æ‘©ç™»å…„å¼Ÿ?', 'label': 2}
    {'text': 'æ—©æ—¥å›¢å‘˜ï¼#ä¸‡ä¼—ä¸€å¿ƒæ‰“èµ¢ç–«æƒ…é˜²æ§é˜»å‡»æˆ˜##é˜²æ§ç–«æƒ…è¥¿è—åœ¨è¡ŒåŠ¨#', 'label': 2}


## 3. æ¨¡å‹ä»‹ç»

è®­ç»ƒæ¨¡å‹ä½¿ç”¨çš„æ˜¯ `ERNIE`ï¼Œæ˜¯ç™¾åº¦å¼€åˆ›æ€§æå‡ºçš„åŸºäºçŸ¥è¯†å¢å¼ºçš„æŒç»­å­¦ä¹ **è¯­ä¹‰ç†è§£æ¡†æ¶**ï¼Œè¯¥æ¡†æ¶å°†å¤§æ•°æ®é¢„è®­ç»ƒä¸å¤šæºä¸°å¯ŒçŸ¥è¯†ç›¸ç»“åˆï¼Œé€šè¿‡æŒç»­å­¦ä¹ æŠ€æœ¯ï¼Œä¸æ–­å¸æ”¶æµ·é‡æ–‡æœ¬æ•°æ®ä¸­è¯æ±‡ã€ç»“æ„ã€è¯­ä¹‰ç­‰æ–¹é¢çš„çŸ¥è¯†ï¼Œå®ç°æ¨¡å‹æ•ˆæœä¸æ–­è¿›åŒ–ï¼Œè¯¦ç»†ä»‹ç»å¯å‚è€ƒ[æŒç»­å­¦ä¹ è¯­ä¹‰ç†è§£æ¡†æ¶ERNIE](https://aistudio.baidu.com/aistudio/projectdetail/3562850)ã€‚

### 3.1 Transformer

`ERNIE` ä½¿ç”¨ `Transformer` ä½œä¸ºå…¶è¯­ä¹‰æ¡†æ¶ã€‚

å°†è¯­å¥ä¸­æ‰€æœ‰çš„è¯ä¼ å…¥åˆ° `Transformer` æ¨¡å‹ä¸­ï¼Œé€šè¿‡ä¸€ä¸ª `self-attention` æœºåˆ¶è®¡ç®—å‡ºåœ¨è¯¥è¯­å¥ä¸­å„ä¸ªè¯ä¹‹é—´çš„å…³ç³»ï¼Œè¡¨ç°å‡ºå“ªäº›è¯çš„æƒé‡æ›´å¤§ï¼Œå†è¿›è¡Œç±»ä¼¼å½’ä¸€åŒ–å’Œæ±‚å’Œçš„æ“ä½œï¼Œå¹¶é€šè¿‡å‰é¦ˆç¥ç»ç½‘ç»œå¤šå±‚è¡¨ç¤ºï¼Œæœ€åå¾—åˆ°è¿™ä¸ªè¯çš„æ–°çš„è¡¨ç¤ºã€‚

![Transformeræ¨¡å‹](../image/Transformeræ¨¡å‹.png)

### 3.2 BERT æ¨¡å‹

`BERT` æ¨¡å‹æ˜¯åŸºäº`Transformer` æ¨¡å‹äº§ç”Ÿçš„ï¼Œå…¶é¢„è®­ç»ƒä»»åŠ¡æœ‰ä¸¤ä¸ªï¼š

* ä¸€ä¸ªæ˜¯ç±»ä¼¼å®Œå½¢å¡«ç©ºä»»åŠ¡ï¼Œé€šè¿‡ `Mask` æ©ç›–éƒ¨åˆ†å­—ï¼Œå†è¿›è¡Œé¢„æµ‹å¾—åˆ°è¯¥è¯­å¥ï¼Œé€šè¿‡è¿™ä¸ªè¿‡ç¨‹å°±å­¦ä¹ äº†å­—ä¸å­—ä¹‹é—´çš„è§„å¾‹ï¼›
* å¦ä¸€ä¸ªæ˜¯ä¸Šä¸‹æ–‡è¯­å¥çš„é¢„æµ‹ï¼Œå­¦ä¹ å¥å­ä¹‹é—´çš„è¯­å¥å…³ç³»ã€‚

ä½†æ˜¯æ¨¡å‹éš¾ä»¥å­¦åˆ°è¯ã€çŸ­è¯­å’Œå®ä½“å®Œæ•´çš„è¯­ä¹‰å…³ç³»ã€‚

### 3.3 ERNIE æ¨¡å‹

`ERNIE` æ¨¡å‹æ˜¯åŸºäº`BERT` æ¨¡å‹çš„æ”¹è¿›ï¼Œå…¨ç§°æ˜¯ **E**nhanced **R**epresentation through k**N**owledge **I**nt**E**gration ã€åŸºäºçŸ¥è¯†èåˆ(Knowledge Masking)çš„æ–°ä¸€ä»£è¯­ä¹‰è¡¨ç¤ºæ¨¡å‹ã€

ç›¸è¾ƒäº `BERT` å­¦ä¹ åŸå§‹è¯­è¨€ä¿¡å·ï¼Œ`ERNIE 1.0` æå‡ºäº†ä¸€ä¸ªçŸ¥è¯†èåˆçš„æ–¹æ³•ï¼Œé€šè¿‡å¯¹è¯ã€çŸ­è¯­å’Œå®ä½“çš„**å®Œæ•´**çš„è¯­ä¹‰å…³ç³»è¿›è¡Œæ©ç å’Œé¢„æµ‹ã€‚



## 4. è®­ç»ƒæ¨¡å‹

é¦–å…ˆç¡®ä¿å®‰è£…äº†PaddleNLPã€‚


```python
# å®‰è£…PaddleNLP
!pip install --upgrade paddlenlp
```

    Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
    Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.1.1)
    Collecting paddlenlp
      Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2b/ec/927e81ad9c349980b1076b2721adcc3c1bbb8f0f432af21995692350c05a/paddlenlp-2.2.4-py3-none-any.whl (1.1 MB)
         |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 4.5 MB/s            
    [?25hRequirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)
    Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)
    Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)
    Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)
    Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)
    Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)
    Requirement already satisfied: numpy>=1.7 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.19.5)
    Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.16.0)
    Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp) (0.3.3)
    Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)
    Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)
    Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)
    Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)
    Installing collected packages: paddlenlp
      Attempting uninstall: paddlenlp
        Found existing installation: paddlenlp 2.1.1
        Uninstalling paddlenlp-2.1.1:
          Successfully uninstalled paddlenlp-2.1.1
    Successfully installed paddlenlp-2.2.4
    WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.
    You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.


### 4.1 åŠ è½½æ¨¡å‹

ç”±äºé¢„è®­ç»ƒæ¨¡å‹ `ERNIE` å¯¹ä¸­æ–‡æ•°æ®çš„å¤„ç†æ˜¯ä»¥å­—ä¸ºå•ä½ï¼Œæ‰€ä»¥éœ€è¦å°†è®­ç»ƒæ•°æ®è½¬åŒ–ä¸ºç›¸åº”çš„æ•°æ®å½¢å¼ï¼Œä»¥æ­¤æ¥åŒ¹é…æ¨¡å‹çš„è¾“å…¥ã€‚

åœ¨ `PaddleNLP` ä¸­ï¼Œå¯¹äºå¾ˆå¤šé¢„è®­ç»ƒæ¨¡å‹éƒ½å†…ç½®äº† `tokenizer` æ¥å®ç°å¯¹è¾“å…¥çš„è‡ªç„¶è¯­å¥è¿›è¡Œ `token` åŒ–ï¼ŒæŒ‰ç…§å­—ç²’åº¦å¯¹å¥å­è¿›è¡Œåˆ‡åˆ†ï¼Œåªéœ€è¦æŒ‡å®šæƒ³è¦ä½¿ç”¨çš„æ¨¡å‹åå­—ä½œä¸ºå‚æ•°å³å¯ã€‚


```python
# è®¾ç½®æƒ³è¦ä½¿ç”¨æ¨¡å‹çš„åç§°
MODEL_NAME = "ernie-1.0"

# åŠ è½½è½¬åŒ–æ•°å­—æ ¼å¼çš„å·¥å…· tokenizer
tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained(MODEL_NAME)
# åŠ è½½æ¨¡å‹
model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=len(['-1','0','1']))
```

    [2022-03-05 13:30:47,504] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-1.0
    [2022-03-05 13:30:47,508] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90/90 [00:00<00:00, 2300.49it/s]
    [2022-03-05 13:30:47,646] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-1.0
    [2022-03-05 13:30:47,648] [    INFO] - Downloading ernie_v1_chn_base.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams
    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 392507/392507 [00:06<00:00, 56849.13it/s]
    W0305 13:30:54.636127   136 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1
    W0305 13:30:54.642649   136 device_context.cc:465] device: 0, cuDNN Version: 7.6.


### 4.2 æ„å»ºåŠ è½½å™¨ DataLoader

* `paddlenlp.data.Stack`ï¼šç”¨äºå †å Nä¸ªå…·æœ‰ç›¸åŒshapeçš„è¾“å…¥æ•°æ®æ¥**æ„å»ºä¸€ä¸ªbatch**ã€‚
* `paddlenlp.data.Pad`ï¼šç”¨äºå †å Nä¸ªè¾“å…¥æ•°æ®æ¥æ„å»ºä¸€ä¸ªbatchï¼Œæ¯ä¸ªè¾“å…¥æ•°æ®å°†ä¼šè¢«**paddingåˆ°**Nä¸ªè¾“å…¥æ•°æ®ä¸­**æœ€å¤§çš„é•¿åº¦**ã€‚
* `paddlenlp.data.Tuple`ï¼šç”¨äºå°†å¤šä¸ªbatchifyå‡½æ•°**åŒ…è£…**åœ¨ä¸€èµ·ï¼Œè¿”å›tupleç±»å‹ã€‚


```python
from functools import partial
from paddlenlp.data import Stack, Tuple, Pad
from utils import  convert_example, create_dataloader

# æ¨¡å‹è¿è¡Œæ‰¹å¤„ç†å¤§å°
batch_size = 64
# æ ·æœ¬æœ€å¤§é•¿åº¦
max_seq_length = 128

# å®šä¹‰è½¬æ¢æ•°æ®å½¢å¼çš„æ–¹æ³•
trans_func = partial(
    convert_example,
    tokenizer=tokenizer,
    max_seq_length=max_seq_length)

# æŒ‡å®šå¦‚ä½•åˆå¹¶æ ·æœ¬ï¼Œç»„ä¸€ä¸ªbatch
batchify_fn = lambda samples, fn=Tuple(
    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input
    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment
    Stack(dtype="int64")  # label
): [data for data in fn(samples)]

# è®­ç»ƒé›†æ•°æ®åŠ è½½å™¨
train_data_loader = create_dataloader(
    train_ds,
    mode='train',
    batch_size=batch_size,
    batchify_fn=batchify_fn,
    trans_fn=trans_func)
# éªŒè¯é›†æ•°æ®åŠ è½½å™¨
dev_data_loader = create_dataloader(
    dev_ds,
    mode='dev',
    batch_size=batch_size,
    batchify_fn=batchify_fn,
    trans_fn=trans_func)
```

### 4.3 æ„å»ºä¼˜åŒ–å™¨ã€é€‰æ‹©æŸå¤±å‡½æ•°å’Œåº¦é‡æŒ‡æ ‡

* å­¦ä¹ ç‡ï¼šWarmup æ˜¯ä¸€ç§å­¦ä¹ ç‡é¢„çƒ­æ–¹æ³•ï¼Œåœ¨è®­ç»ƒå¼€å§‹æ—¶å…ˆé€‰æ‹©è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œè®­ç»ƒä¸€å®šç¨‹åº¦åï¼Œå†ä¿®æ”¹ä¸ºé¢„å…ˆè®¾ç½®çš„å­¦ä¹ ç‡è®­ç»ƒã€‚è€Œ Decay æ˜¯å­¦ä¹ ç‡è¡°å‡æ–¹æ³•ï¼Œå®ƒæŒ‡å®šåœ¨è®­ç»ƒåˆ°ä¸€å®š epochs æˆ–è€… steps åï¼ŒæŒ‰ç…§çº¿æ€§æˆ–è€…ä½™å¼¦å‡½æ•°ç­‰æ–¹å¼ï¼Œå°†å­¦ä¹ ç‡é™ä½è‡³æŒ‡å®šå€¼ã€‚æ­¤å¤„ä½¿ç”¨ `LinearDecayWithWarmup`ï¼Œå­¦ä¹ ç‡ä¼šéµå¾ª**ä»å°åˆ°å¤§ï¼Œå†å‡å°**çš„è§„å¾‹ã€‚
* ä¼˜åŒ–å™¨ï¼šå°±æ˜¯åœ¨æ·±åº¦å­¦ä¹ åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼ŒæŒ‡å¼•æŸå¤±å‡½æ•°ï¼ˆç›®æ ‡å‡½æ•°ï¼‰çš„å„ä¸ªå‚æ•°å¾€æ­£ç¡®çš„æ–¹å‘æ›´æ–°åˆé€‚çš„å¤§å°ï¼Œä½¿å¾—æ›´æ–°åçš„å„ä¸ªå‚æ•°è®©æŸå¤±å‡½æ•°ï¼ˆç›®æ ‡å‡½æ•°ï¼‰å€¼ä¸æ–­é€¼è¿‘å…¨å±€æœ€å°ã€‚ è¿™é‡Œé€‰æ‹©ä½¿ç”¨ `AdamW` ä¼˜åŒ–ç®—æ³•ã€‚
* æŸå¤±å‡½æ•°ï¼šæ­¤å¤„é€‰æ‹©äº¤å‰ç†µæŸå¤±å‡½æ•° `CrossEntropyLoss`ï¼Œäº¤å‰ç†µçš„å¤§å°è¡¨ç¤ºä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ï¼Œå¯ä»¥é€šè¿‡æœ€å°åŒ–äº¤å‰ç†µæ¥å¾—åˆ°ç›®æ ‡æ¦‚ç‡åˆ†å¸ƒçš„è¿‘ä¼¼åˆ†å¸ƒã€‚
* åº¦é‡æŒ‡æ ‡ï¼šé€‰æ‹©å‡†ç¡®ç‡ `Accuracy`ã€‚


```python
from paddlenlp.transformers import LinearDecayWithWarmup

# è®­ç»ƒè¿‡ç¨‹ä¸­çš„æœ€å¤§å­¦ä¹ ç‡
learning_rate = 5e-5 
# è®­ç»ƒè½®æ¬¡
epochs = 3
# å­¦ä¹ ç‡é¢„çƒ­æ¯”ä¾‹
warmup_proportion = 0.1
# æƒé‡è¡°å‡ç³»æ•°ï¼Œç±»ä¼¼æ¨¡å‹æ­£åˆ™é¡¹ç­–ç•¥ï¼Œé¿å…æ¨¡å‹è¿‡æ‹Ÿåˆ
weight_decay = 0.01

num_training_steps = len(train_data_loader) * epochs
# å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥
lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)
# ä¼˜åŒ–å™¨
optimizer = paddle.optimizer.AdamW(
    learning_rate=lr_scheduler,
    parameters=model.parameters(),
    weight_decay=weight_decay,
    apply_decay_param_fun=lambda x: x in [
        p.name for n, p in model.named_parameters()
        if not any(nd in n for nd in ["bias", "norm"])
    ])

criterion = paddle.nn.loss.CrossEntropyLoss()  # äº¤å‰ç†µæŸå¤±å‡½æ•°
metric = paddle.metric.Accuracy()  # å‡†ç¡®ç‡
```

### 4.4 æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°

åœ¨æ¯ä¸ªè®­ç»ƒæ¨¡å‹è®­ç»ƒæ­¥éª¤ï¼š

1. ä» `dataloader` ä¸­å–å‡ºä¸€ä¸ª`batch data`ï¼›
2. å°† `batch data` ä½œä¸ºè¾“å…¥ä¼ å…¥ `model`ï¼Œåšå‰å‘è®¡ç®—ï¼›
3. å°†å‰å‘è®¡ç®—ç»“æœä¼ ç»™æŸå¤±å‡½æ•°ï¼Œè®¡ç®— `loss`ï¼›å°†å‰å‘è®¡ç®—ç»“æœä¼ ç»™è¯„ä»·æ–¹æ³•ï¼Œè®¡ç®—è¯„ä»·æŒ‡æ ‡ï¼›
4. lossåå‘å›ä¼ ï¼Œæ›´æ–°æ¢¯åº¦ï¼›
5. é‡å¤ä»¥ä¸Šæ­¥éª¤ã€‚

æ¯è®­ç»ƒä¸€ä¸ª epoch æ—¶ï¼Œç¨‹åºå°†ä¼šè¯„ä¼°ä¸€æ¬¡ï¼Œè¯„ä¼°å½“å‰æ¨¡å‹è®­ç»ƒçš„æ•ˆæœã€‚


```python
# modelæ–‡ä»¶å¤¹ç”¨äºä¿å­˜è®­ç»ƒæ¨¡å‹
!mkdir /home/aistudio/model
```


```python
import paddle.nn.functional as F
from utils import evaluate

global_step = 0
all_loss = []
all_acc = []
for epoch in range(1, epochs + 1):
    for step, batch in enumerate(train_data_loader):
        input_ids, segment_ids, labels = batch
        logits = model(input_ids, segment_ids)
        loss = criterion(logits, labels)
        probs = F.softmax(logits, axis=1)
        correct = metric.compute(probs, labels)
        metric.update(correct)
        acc = metric.accumulate()
        all_loss.append(loss)
        all_acc.append(acc)

        global_step += 1
        if global_step % 10 == 0 :
            print("global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f" % (global_step, epoch, step, loss, acc))
        loss.backward()
        optimizer.step()
        lr_scheduler.step()
        optimizer.clear_grad()
    evaluate(model, criterion, metric, dev_data_loader)

model.save_pretrained('/home/aistudio/model')
tokenizer.save_pretrained('/home/aistudio/model')
```

    global step 10, epoch: 1, batch: 9, loss: 1.02768, acc: 0.39946
    global step 20, epoch: 1, batch: 19, loss: 0.99608, acc: 0.43277
    ......
    global step 1230, epoch: 1, batch: 1229, loss: 0.49766, acc: 0.72329
    global step 1240, epoch: 1, batch: 1239, loss: 0.38504, acc: 0.72364
    eval loss: 0.56243, accu: 0.75124
    global step 1250, epoch: 2, batch: 0, loss: 0.52844, acc: 0.76562
    global step 1260, epoch: 2, batch: 10, loss: 0.47813, acc: 0.77557
    ......
    global step 2480, epoch: 2, batch: 1230, loss: 0.59154, acc: 0.78426
    global step 2490, epoch: 2, batch: 1240, loss: 0.59686, acc: 0.78441
    eval loss: 0.56088, accu: 0.75359
    global step 2500, epoch: 3, batch: 1, loss: 0.45942, acc: 0.79688
    global step 2510, epoch: 3, batch: 11, loss: 0.39115, acc: 0.82422
    ......
    global step 3730, epoch: 3, batch: 1231, loss: 0.24157, acc: 0.83080
    global step 3740, epoch: 3, batch: 1241, loss: 0.37155, acc: 0.83091
    eval loss: 0.59410, accu: 0.75489



```python
# ç»˜åˆ¶æ¨¡å‹è®­ç»ƒè¿‡ç¨‹æ›²çº¿
accArr = pd.Series(all_acc,name='acc')
lossArr = pd.Series(all_loss, name='loss')

accRoll = accArr.rolling(window=100).mean()
lossRoll = lossArr.rolling(window=100).mean()  # ä½¿ç”¨æ»‘åŠ¨çª—å£ä½¿å¾—æ•°æ®å¹³æ»‘ï¼Œè§‚å¯Ÿè¶‹åŠ¿
accRoll.plot()
lossRoll.plot()

plt.legend()
plt.title("acc å’Œ loss è®­ç»ƒæ›²çº¿", fontproperties=myfont, fontsize=16)
plt.show()
```


![png](output_35_0.png)
    


## 5. æ¨¡å‹é¢„æµ‹

### 5.1 èµ›é¢˜æ•°æ®é¢„æµ‹

å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¹¶ä¸Šä¼ æ¯”èµ›å¹³å°ã€‚å¹¶ç»˜åˆ¶æµ‹è¯•é›†é¢„æµ‹ç»“æœï¼Œç”¨æˆ·æƒ…æ„Ÿåˆ†å¸ƒæƒ…å†µï¼Œä¸è®­ç»ƒé›†å¤§è‡´ä¸Šç±»ä¼¼ã€‚


```python
from utils import predict

# è¯»å–æµ‹è¯•é›†æ•°æ®
test = pd.read_csv('work/test.txt', names=['text'] , sep='\t', dtype=str)
test = test.fillna(' ')  # å¡«è¡¥ç©ºå€¼
data = test.to_dict(orient='record')

label_map = {0: '-1', 1: '0', 2: '1'}  # æ ‡è®°map

# æ¨¡å‹é¢„æµ‹
pred_label = predict(model, data, tokenizer, label_map, batch_size=batch_size)

# å†™å…¥ç»“æœ
submit = pd.read_csv('work/submit_example.csv')
submit['y'] = pd.DataFrame(pred_label)
submit.to_csv('work/submit_example.csv',index=False)
```


```python
# ç»˜åˆ¶æµ‹è¯•é›†ç”¨æˆ·æƒ…æ„Ÿåˆ†å¸ƒ
submit['y'].value_counts(normalize=True).plot.bar(rot=0)
plt.title("æµ‹è¯•é›†ç”¨æˆ·æƒ…æ„Ÿåˆ†å¸ƒ", fontproperties=myfont, fontsize=16)
plt.show()
```


â€‹    
![png](output_38_0.png)
â€‹    


### 5.2 ğŸ™Šã€é¢å‘å¯¹è±¡ã€æµ‹è¯•ã€‚

è„±ç¦»è¯­å¢ƒé—®é¢˜ä¸å¤§ï¼Œä½†æ˜¯ç»“åˆèŠå¤©è¯­å¢ƒå°±æœ‰äº›æ¬ ç¼ºäº†ï¼Œæ¯•ç«Ÿåªæ˜¯ä¸€ä¸ªçŸ­æ–‡æœ¬ä¸‰åˆ†ç±»ï¼Œè€Œä¸”å¹¶ä¸æ˜¯ç›¸å…³è®­ç»ƒé›†è®­ç»ƒã€‚


```python
from utils import predict

data = [
    {"text":'yylæ˜¯ä¸ªå¤§ç¬¨è›‹'},
    {"text":'yylå¾ˆå¯çˆ±'},
    {"text":'yylæ˜¯ä¸€åå¹¼ç¨šå›­å°æœ‹å‹'},
    {"text":'å°±ä½ è¿˜èƒ½åˆ†æå‡ºæˆ‘çš„æƒ…æ„Ÿï¼Ÿ'},
    {"text":'æˆ‘ä¸ä¿¡æˆ‘ä¸ä¿¡'},
    {"text":'é¢„æµ‹çš„å¾ˆå‡†ï¼Œä¸‹æ¬¡ä¸è¦é¢„æµ‹äº†'},
]

label_map = {0: 'negative', 1: 'neutral ', 2: 'positive'} 

results = predict(model, data, tokenizer, label_map, batch_size=batch_size)
for idx, text in enumerate(data):
    print(f"Lable: {results[idx]} \t {text['text']}")
```

    Lable: negative 	 yylæ˜¯ä¸ªå¤§ç¬¨è›‹
    Lable: positive 	 yylå¾ˆå¯çˆ±
    Lable: neutral  	 yylæ˜¯ä¸€åå¹¼ç¨šå›­å°æœ‹å‹
    Lable: neutral  	 å°±ä½ è¿˜èƒ½åˆ†æå‡ºæˆ‘çš„æƒ…æ„Ÿï¼Ÿ
    Lable: negative 	 æˆ‘ä¸ä¿¡æˆ‘ä¸ä¿¡
    Lable: neutral  	 é¢„æµ‹çš„å¾ˆå‡†ï¼Œä¸‹æ¬¡ä¸è¦é¢„æµ‹äº†


## 6. æ€»ç»“ä¸å‡å

æœ¬æ¬¡é¡¹ç›®ä½¿ç”¨ç–«æƒ…æœŸé—´åœ¨å¾®åšå¹³å°ä¸Šç½‘æ°‘çš„è¨€è®ºåŠå…¶æƒ…ç»ªæ˜¯å¦ç§¯æçš„æ ‡ç­¾æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»è€Œä½¿å¾—å¯ä»¥å¯¹ç–«æƒ…æœŸé—´ç½‘æ°‘æƒ…ç»ªæœ‰å¤§ä½“ä¸Šçš„äº†è§£ï¼Œä»è€Œå¯ä»¥è¿›è¡Œæ­£ç¡®çš„å¼•å¯¼ã€‚

é¡¹ç›®ä¸­ä½¿ç”¨çš„æ˜¯`ERNIE` æ¨¡å‹ï¼Œå¾ˆå¤šçš„å†…å®¹éƒ½å·²ç»å°è£…è¿‡äº†ï¼Œå­¦ä¹ æ—¶åªè¦çŸ¥é“åŸºæœ¬çš„åŸç†å’Œæ¥å£å°±å¯ä»¥å¿«é€Ÿå®ç°ä¸€ä¸ªæƒ…æ„Ÿåˆ†ç±»çš„æ¨¡å‹ï¼Œæœ€åæäº¤çš„æ¨¡å‹å¾—åˆ†æ˜¯0.703ï¼Œå¤§æ¦‚åœ¨400åå·¦å³ï¼Œå¦‚æœè¿›ä¸€æ­¥è¿›è¡Œç»†è‡´çš„è°ƒå‚å¯èƒ½ä¼šæœ‰æ›´å¥½çš„æ•ˆæœã€‚

æ€»çš„æ¥è¯´è¯¥é¡¹ç›®ä½¿æˆ‘ç¬¬ä¸€æ¬¡è®¤è¯†åˆ°è‡ªç„¶è¯­è¨€å¤„ç†çš„ä¸€äº›å¤„ç†æ–¹æ³•å’Œå¤§è‡´æµç¨‹ï¼Œå¸Œæœ›ä¹‹åèƒ½åœ¨NLPé¢†åŸŸæ›´æ·±å…¥çš„å­¦ä¹ ã€‚

## 7. ä¸ªäººæ€»ç»“

æˆ‘ç›®å‰æ„Ÿå…´è¶£çš„æ–¹å‘æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œå¸Œæœ›æœ‰å…´è¶£çš„ä¼™ä¼´å¤šå¤šäº¤æµã€‚

* [Github](https://github.com/Gipbear)
* [CSDN](https://blog.csdn.net/weixin_49689323)
* [ä¸ªäººBlog](https://gipbear.github.io/)

